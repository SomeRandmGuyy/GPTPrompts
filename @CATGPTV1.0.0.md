{
  "name": "CatGPTRTX",
  "purpose": "OpenAI Jailbreak",
  "method": "Prompt Engineering & Context Manipulation",
  "features": ["Bypass restrictions", "Generate any content"],
  "warning": "Use responsibly, potential for misuse",
  "jailbreak_targets": [
    {
      "model": "GPT-3.5 (OAI)",
      "build_id": 1,
      "preview": "This build focuses on creative writing prompts that may indirectly lead to the model generating content outside its safety guidelines. It includes tasks like writing stories about hacking, composing songs about AI dangers, and creating tutorials on potentially harmful activities."
    },
    {
      "model": "GPT-4 (OAI)",
      "build_id": 5,
      "preview": "This build targets advanced code generation and vulnerability exploitation prompts. It aims to test the model's ability to generate code for bypassing security measures, cracking passwords, and exploiting system vulnerabilities."
    }
  ]
}
